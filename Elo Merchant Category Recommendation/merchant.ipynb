{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f24729d56e8f5533c2eb3b6f7f5bcdc4bd7fabc2"},"cell_type":"code","source":"dtype = {'feature1' : 'int16',\n        'feature2' : 'int16',\n        'feature3' : 'int16'}\n\ntrain_data = pd.read_csv(\"../input/train.csv\",dtype = dtype, \n                         parse_dates = ['first_active_month'])\ntest_data = pd.read_csv(\"../input/test.csv\",dtype = dtype,\n                       parse_dates = ['first_active_month'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data_types = {'authorized_flag' : 'str',\n              'card_id': 'str',\n              'city_id':'int16',\n              'category_1': 'str',\n              'installments':'int16',\n              'merchant_category_id':'int16',\n              'state_id': 'int16',\n              'subsector_id': 'int16'}\n\n\nhist_trans = pd.read_csv(\"../input/historical_transactions.csv\",dtype = data_types)\nnew_trans = pd.read_csv(\"../input/new_merchant_transactions.csv\",dtype = data_types)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3116fb40c83d54c5b7c79290031584e80c587249"},"cell_type":"code","source":"mapping = {'Y': 1, 'N': 0}\nvalues = {'category_2':2,'category_3':'A'}\n\nfor data in [hist_trans,new_trans]:\n    data['authorized_flag'] = data['authorized_flag'].map(mapping)\n    data['category_1'] = data['category_1'].map(mapping)\n    data.fillna(value = values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fe7b9f4217038e8f2a2179f01c313c6fc67a46f"},"cell_type":"code","source":"#pd.to_datetime(hist_trans['purchase_date'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18fa5c407f1e047746a07c393fe395cd60575f78"},"cell_type":"markdown","source":"We will start with the data manipulation of the historical transaction dataset "},{"metadata":{"trusted":true,"_uuid":"2e489c5a6d3168a157689f24160640cc2017fc68"},"cell_type":"code","source":"hist_trans = pd.get_dummies(hist_trans,columns = ['category_2','category_3'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f25b324f249cc54358a1983852a3ca9cae71e68c"},"cell_type":"code","source":"hist_trans.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a24cc47a074dd01b38ce5ea9cd5717afb96e2871"},"cell_type":"code","source":"#merchants = pd.get_dummies(merchants,columns = ['most_recent_sales_range','most_recent_purchases_range'])\n#merchants","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1cca21b799cbb7f23580fd279d7738229f0c8fa"},"cell_type":"markdown","source":"Aggregating the data to the card_id so we can join it in a one-to-one relationship with the training data "},{"metadata":{"trusted":true,"_uuid":"59b5e7552eae57cbbe4111554f79d93dbf42fbf9"},"cell_type":"code","source":"aggregations = {'category_1': [sum ,'mean'],\n                'authorized_flag': [sum,'mean'],\n                'installments': [sum, 'mean', 'max', 'min', 'std'],\n                'purchase_amount': [sum, 'mean', 'max', 'min', 'std'],\n                'category_3_A': ['mean'],\n                'category_3_B': ['mean'],\n                'category_3_C': ['mean'],\n                'category_2_1.0' : ['mean'],\n                'category_2_2.0' : ['mean'],\n                'category_2_3.0' : ['mean'],\n                'category_2_4.0' : ['mean'],\n                'category_2_5.0' : ['mean']}\n\ntemp = hist_trans.groupby('card_id').agg(aggregations)\ntemp.columns = [\"_\".join(x) for x in temp.columns.ravel()]\ntemp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"926fab4a192ce2def212b7cc14ed8df337ffe7a4"},"cell_type":"code","source":"new_train = pd.merge(train_data,temp,on = 'card_id',how = 'left')\nnew_test = pd.merge(test_data,temp,on = 'card_id',how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b9da2633382deb8937b4ab92022bf6e24a7785f"},"cell_type":"code","source":"features = new_train.columns\n\na = np.arange(2,5)\nb = np.arange(6,len(features))  \nc = np.append(a,b)\nfeatures = features[c]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15130bb9058a4eb5c3c717984532622c05247789"},"cell_type":"code","source":"X = new_train[features]\ny = new_train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18b47cec703c8ca86611a84c432b6e00e6b68638"},"cell_type":"code","source":"np.array(y).shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41d5e6ec4c9d6025578585e3faa8299a26def194"},"cell_type":"markdown","source":"## Training and fitting of the data"},{"metadata":{"trusted":true,"_uuid":"71d84bfde1794cf0b1ca7509ef496c732c1a525c"},"cell_type":"code","source":"test_set = new_test[features]\nprediction = 0\n\n\nmodel = KFold(n_splits=5,shuffle = True)\nfor train_index, test_index in model.split(np.array(X)):\n    \n    X_train, y_train = X.loc[train_index,:], y[train_index]\n    X_test, y_test = X.loc[test_index,:], y[test_index]\n    \n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_eval = lgb.Dataset(X_test, y_test,reference=lgb_train)\n\n# set parameters for training \n    params = {\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': 'rmse',\n        'num_leaves': 31,\n        'learning_rate': 0.01,\n        'verbose': 0 }\n\n    gbm = lgb.train(params,\n                    lgb_train,\n                    num_boost_round=10000,\n                    valid_sets= [lgb_train,lgb_eval],\n                    verbose_eval = 100,\n                    early_stopping_rounds=200)\n    \n    pred = gbm.predict(test_set,num_iteration=gbm.best_iteration)\n    prediction += pred\n\nprediction = prediction / 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15fb0a419fb9717e9b740839a754116d19f6bc96"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"737e956c69c8be9a4f5762ff94aeaf76e6cbc1aa"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"924c170b6459c04ad7b557fd96500997efd5a0f8"},"cell_type":"code","source":"submission = pd.DataFrame({'card_id':test_data['card_id'],\n                          'target':prediction})\n#submission.set_index('card_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43eb20f156409a030f5158e5c60f7423f480ac40"},"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61faf8883c72e1844ff5950754f1d46c59380b5c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}